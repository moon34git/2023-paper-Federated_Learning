{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhmoon/venvFL/env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda using PyTorch 1.13.1+cu117 and Flower 1.3.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import MNIST\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import flwr as fl\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
    "print(\n",
    "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1]\n",
    "b = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.1307,), (0.3081,)),\n",
    "    Lambda(lambda x: torch.flatten(x))])\n",
    "\n",
    "with open('/home/jhmoon/venvFL/2023-paper-Federated_Learning/Data/trainset5000.pickle', 'rb') as trs:\n",
    "    trainset = pickle.load(trs)\n",
    "with open('/home/jhmoon/venvFL/2023-paper-Federated_Learning/Data/testset.pickle', 'rb') as tts:\n",
    "    testset = pickle.load(tts)\n",
    "\n",
    "trainset.transform = transform\n",
    "testset.transform = transform\n",
    "\n",
    "partition_size = len(trainset) // num_clients\n",
    "lengths = [partition_size] * num_clients\n",
    "datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "# Split each partition into train/val and create DataLoader\n",
    "trainloaders = []\n",
    "valloaders = []\n",
    "for ds in datasets:\n",
    "    len_val = len(ds) // 10  # 10 % validation set\n",
    "    len_train = len(ds) - len_val\n",
    "    lengths = [len_train, len_val]\n",
    "    ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "    trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "    valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "testloader = DataLoader(testset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_y_on_x(x, y):\n",
    "    \"\"\"Replace the first 10 pixels of data [x] with one-hot-encoded label [y]\n",
    "    \"\"\"\n",
    "    x_ = x.clone()\n",
    "    x_[:, :10] *= 0.0\n",
    "    x_[range(x.shape[0]), y] = x.max()\n",
    "  \n",
    "    return x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super().__init__()\n",
    "        # self.layers = []\n",
    "        # for d in range(len(dims) - 1):\n",
    "        #     self.layers += [Layer(dims[d], dims[d + 1])]\n",
    "\n",
    "        self.layer1 = Layer(dims[0], dims[1])\n",
    "        self.layer2 = Layer(dims[1], dims[2])\n",
    "   \n",
    "\n",
    "    # def test(self, x):\n",
    "    #     goodness_per_label = []\n",
    "    #     for label in range(10):\n",
    "    #         h = overlay_y_on_x(x, label)\n",
    "    #         goodness = []\n",
    "    #         for layer in self.layers:\n",
    "    #             h = layer(h)\n",
    "    #             goodness += [h.pow(2).mean(1)]\n",
    "    #         goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
    "    #     goodness_per_label = torch.cat(goodness_per_label, 1)\n",
    "    #     return goodness_per_label.argmax(1)\n",
    "\n",
    "    def test(self, x):\n",
    "        goodness_per_label = []\n",
    "        for label in range(10):\n",
    "            h = overlay_y_on_x(x, label)\n",
    "            goodness = []\n",
    "            h = self.layer1(h)\n",
    "            goodness += [h.pow(2).mean(1)]\n",
    "            h = self.layer2(h)\n",
    "            goodness += [h.pow(2).mean(1)]\n",
    "            goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
    "        goodness_per_label = torch.cat(goodness_per_label, 1)\n",
    "        return goodness_per_label.argmax(1)\n",
    "\n",
    "\n",
    "    # def train(self, x_pos, x_neg):\n",
    "    #     h_pos, h_neg = x_pos, x_neg\n",
    "    #     for i, layer in enumerate(self.layers):\n",
    "    #         print('training layer', i, '...')\n",
    "    #         h_pos, h_neg = layer.train(h_pos, h_neg)\n",
    "\n",
    "    def train(self, x_pos, x_neg):\n",
    "        h_pos, h_neg = x_pos, x_neg\n",
    "        print('training layer', 0, '...')\n",
    "        h_pos = self.layer1.train(h_pos, h_neg)\n",
    "        print('training layer', 1, '...')\n",
    "        h_neg = self.layer2.train(h_pos, h_neg)\n",
    "\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features,\n",
    "                 bias=True, device=None, dtype=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.opt = optim.Adam(self.parameters(), lr=0.03)\n",
    "        self.threshold = 2.0\n",
    "        self.num_epochs = 1000\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
    "        # x_direction = x_direction.to(DEVICE)\n",
    "        print(f'x in cuda? : {x.is_cuda}, value of x :{x}, shape of x :{x.shape}')\n",
    "        print(f'weight in cuda? : {self.weight.is_cuda}, type of x :{type(self.weight)}, value of x :{self.weight}, shape of x :{self.weight.shape}')\n",
    "        matmul = torch.mm(x_direction, self.weight.T)\n",
    "        bias = self.bias.unsqueeze(0)\n",
    "        output = self.relu(matmul + bias)\n",
    "        return output\n",
    "\n",
    "    def train(self, x_pos, x_neg):\n",
    "        for i in range(self.num_epochs):\n",
    "            g_pos = self.forward(x_pos).pow(2).mean(1)\n",
    "            g_neg = self.forward(x_neg).pow(2).mean(1)\n",
    "            # The following loss pushes pos (neg) samples to\n",
    "            # values larger (smaller) than the self.threshold.\n",
    "            loss = torch.log(1 + torch.exp(torch.cat([\n",
    "                -g_pos + self.threshold,\n",
    "                g_neg - self.threshold]))).mean()\n",
    "            self.opt.zero_grad()\n",
    "            # this backward just compute the derivative and hence\n",
    "            # is not considered backpropagation.\n",
    "            loss.backward()\n",
    "            self.opt.step()\n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters, Client get_parameters {len(get_parameters(self.net))}\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "\n",
    "        # print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        # set_parameters(self.net, parameters)\n",
    "        # train(self.net, self.trainloader, epochs=1)\n",
    "\n",
    "        # Read values from config\n",
    "        server_round = config[\"server_round\"]\n",
    "        local_epochs = config[\"local_epochs\"]\n",
    "\n",
    "        # Use values provided by the config\n",
    "        print(f\"[Client {self.cid}, round {server_round}] fit, config: {config}\")\n",
    "        print(f'Parameter Size (For Client fitting): {len(parameters)}')\n",
    "        set_parameters(self.net, parameters)\n",
    "        \n",
    "        x, y = next(iter(self.trainloader))\n",
    "        # x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        x_pos = overlay_y_on_x(x, y)\n",
    "        rnd = torch.randperm(x.size(0))\n",
    "        x_neg = overlay_y_on_x(x, y[rnd])\n",
    "        self.net.train(x_pos, x_neg)\n",
    "        # print(f'x = {x.is_cuda}')\n",
    "        # print(f'y = {y.is_cuda}')\n",
    "\n",
    "        print('train error:', 1.0 - self.net.test(x).eq(y).float().mean().item())\n",
    "        # self.net.train(self.net, self.trainloader, epochs=local_epochs)\n",
    "\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "    \n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        print(f'Parameter Size (For Client evaluation): {len(parameters)}')\n",
    "        set_parameters(self.net, parameters)\n",
    "        x, y = next(iter(self.valloader))\n",
    "        loss = 0\n",
    "        accuracy = 1.0 - self.net.test(x).eq(y).float().mean().item()\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net([784, 500, 500]).to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    server_round: int,\n",
    "    parameters: fl.common.NDArrays,\n",
    "    config: Dict[str, fl.common.Scalar],\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net([784, 500, 500]).to(DEVICE)\n",
    "    x, y = next(iter(valloaders[0]))\n",
    "    # x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    print(f'Parameter Size (For server evaluation): {len(parameters)}')\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss = 0\n",
    "    accuracy = 1.0 - net.test(x).eq(y).float().mean().item()\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    \"\"\"Return training configuration dict for each round.\n",
    "\n",
    "    Perform two rounds of training with one local epoch, increase to two local\n",
    "    epochs afterwards.\n",
    "    \"\"\"\n",
    "    config = {\n",
    "        \"server_round\": server_round,  # The current round of federated learning\n",
    "        \"local_epochs\": 1 if server_round < 2 else 2,  #\n",
    "    }\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net([784, 500, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_parameters(Net([784, 500, 500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-04-15 17:04:54,998 | app.py:148 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-04-15 17:04:59,370\tINFO worker.py:1535 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "INFO flwr 2023-04-15 17:05:00,694 | app.py:182 | Flower VCE: Ray initialized with resources: {'CPU': 32.0, 'object_store_memory': 34568333721.0, 'memory': 70659445351.0, 'GPU': 1.0, 'node:117.17.189.210': 1.0}\n",
      "INFO flwr 2023-04-15 17:05:00,695 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-04-15 17:05:00,696 | server.py:266 | Using initial parameters provided by strategy\n",
      "INFO flwr 2023-04-15 17:05:00,696 | server.py:88 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Size (For server evaluation): 4\n",
      "x in cuda? : False, value of x :tensor([[ 2.8215, -0.0000, -0.0000,  ..., -0.4242, -0.4242, -0.4242],\n",
      "        [ 2.8215, -0.0000, -0.0000,  ..., -0.4242, -0.4242, -0.4242],\n",
      "        [ 2.8215, -0.0000, -0.0000,  ..., -0.4242, -0.4242, -0.4242],\n",
      "        ...,\n",
      "        [ 2.8215, -0.0000, -0.0000,  ..., -0.4242, -0.4242, -0.4242],\n",
      "        [ 2.8215, -0.0000, -0.0000,  ..., -0.4242, -0.4242, -0.4242],\n",
      "        [ 2.8215, -0.0000, -0.0000,  ..., -0.4242, -0.4242, -0.4242]]), shape of x :torch.Size([32, 784])\n",
      "weight in cuda? : True, type of x :<class 'torch.nn.parameter.Parameter'>, value of x :Parameter containing:\n",
      "tensor([[ 0.0203, -0.0268, -0.0338,  ...,  0.0352,  0.0304,  0.0330],\n",
      "        [ 0.0177,  0.0165,  0.0031,  ..., -0.0110,  0.0188, -0.0168],\n",
      "        [ 0.0083,  0.0263, -0.0314,  ..., -0.0167,  0.0197, -0.0080],\n",
      "        ...,\n",
      "        [-0.0245, -0.0294, -0.0270,  ..., -0.0049, -0.0263,  0.0117],\n",
      "        [-0.0240, -0.0183, -0.0327,  ...,  0.0108, -0.0343, -0.0105],\n",
      "        [ 0.0054,  0.0254, -0.0241,  ..., -0.0072,  0.0209, -0.0205]],\n",
      "       device='cuda:0', requires_grad=True), shape of x :torch.Size([500, 784])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16404/1384846953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Just three rounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mclient_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_resources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/flwr/simulation/app.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[1;32m    196\u001b[0m     hist = _fl(\n\u001b[1;32m    197\u001b[0m         \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/flwr/server/app.py\u001b[0m in \u001b[0;36m_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    199\u001b[0m ) -> History:\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"app_fit: losses_distributed %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_distributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"app_fit: metrics_distributed %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_distributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_initial_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Evaluating initial parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             log(\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/flwr/server/strategy/fedavg.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, server_round, parameters)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mparameters_ndarrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters_to_ndarrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0meval_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters_ndarrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_res\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16404/3938292974.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(server_round, parameters, config)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update model with the latest parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Server-side evaluation loss {loss} / accuracy {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16404/1594740796.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlay_y_on_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mgoodness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mgoodness\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16404/1594740796.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'x in cuda? : {x.is_cuda}, value of x :{x}, shape of x :{x.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'weight in cuda? : {self.weight.is_cuda}, type of x :{type(self.weight)}, value of x :{self.weight}, shape of x :{self.weight.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mmatmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_direction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatmul\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_mm)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ray_print_logs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jhmoon/venvFL/env/lib/python3.7/site-packages/ray/_private/worker.py\", line 787, in print_logs\n",
      "    data = subscriber.poll()\n",
      "  File \"/home/jhmoon/venvFL/env/lib/python3.7/site-packages/ray/_private/gcs_pubsub.py\", line 357, in poll\n",
      "    self._poll_locked(timeout=timeout)\n",
      "  File \"/home/jhmoon/venvFL/env/lib/python3.7/site-packages/ray/_private/gcs_pubsub.py\", line 247, in _poll_locked\n",
      "    self._poll_request(), timeout=timeout\n",
      "  File \"/home/jhmoon/venvFL/env/lib/python3.7/site-packages/grpc/_channel.py\", line 1064, in future\n",
      "    (operations,), event_handler, self._context)\n",
      "  File \"/home/jhmoon/venvFL/env/lib/python3.7/site-packages/grpc/_channel.py\", line 1443, in create\n",
      "    _run_channel_spin_thread(state)\n",
      "  File \"/home/jhmoon/venvFL/env/lib/python3.7/site-packages/grpc/_channel.py\", line 1404, in _run_channel_spin_thread\n",
      "    channel_spin_thread.start()\n",
      "  File \"src/python/grpcio/grpc/_cython/_cygrpc/fork_posix.pyx.pxi\", line 117, in grpc._cython.cygrpc.ForkManagedThread.start\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 852, in start\n",
      "    _start_new_thread(self._bootstrap, ())\n",
      "RuntimeError: can't start new thread\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1,\n",
    "    fraction_evaluate=2,\n",
    "    min_fit_clients=2,\n",
    "    min_evaluate_clients=2,\n",
    "    min_available_clients=2,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    "    evaluate_fn=evaluate,\n",
    "    on_fit_config_fn = fit_config,\n",
    ")\n",
    "\n",
    "client_resources = None\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2,\n",
    "    config=fl.server.ServerConfig(num_rounds=3),  # Just three rounds\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

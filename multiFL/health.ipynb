{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "%matplotlib inline\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/mhealth_raw_data.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     30720\n",
       "2     30720\n",
       "3     30720\n",
       "4     30720\n",
       "9     30720\n",
       "10    30720\n",
       "11    30720\n",
       "5     30720\n",
       "0     30000\n",
       "7     29441\n",
       "8     29337\n",
       "6     28315\n",
       "12    10342\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    " \n",
    "df_majority = df[df.Activity==0]\n",
    "df_minorities = df[df.Activity!=0]\n",
    " \n",
    "df_majority_downsampled = resample(df_majority,n_samples=30000, random_state=42)\n",
    "df = pd.concat([df_majority_downsampled, df_minorities])\n",
    "df.Activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alx</th>\n",
       "      <th>aly</th>\n",
       "      <th>alz</th>\n",
       "      <th>glx</th>\n",
       "      <th>gly</th>\n",
       "      <th>glz</th>\n",
       "      <th>arx</th>\n",
       "      <th>ary</th>\n",
       "      <th>arz</th>\n",
       "      <th>grx</th>\n",
       "      <th>gry</th>\n",
       "      <th>grz</th>\n",
       "      <th>Activity</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154060</th>\n",
       "      <td>-0.68636</td>\n",
       "      <td>-5.2902</td>\n",
       "      <td>4.64530</td>\n",
       "      <td>0.13544</td>\n",
       "      <td>-0.83114</td>\n",
       "      <td>-0.13163</td>\n",
       "      <td>-8.4230</td>\n",
       "      <td>-6.6402</td>\n",
       "      <td>2.98050</td>\n",
       "      <td>-0.93922</td>\n",
       "      <td>0.090349</td>\n",
       "      <td>0.219830</td>\n",
       "      <td>0</td>\n",
       "      <td>subject1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936066</th>\n",
       "      <td>1.00030</td>\n",
       "      <td>-7.7902</td>\n",
       "      <td>-6.74410</td>\n",
       "      <td>-0.26531</td>\n",
       "      <td>-0.14447</td>\n",
       "      <td>-1.09820</td>\n",
       "      <td>2.2046</td>\n",
       "      <td>-7.5497</td>\n",
       "      <td>4.02880</td>\n",
       "      <td>-0.21961</td>\n",
       "      <td>-1.080100</td>\n",
       "      <td>0.303880</td>\n",
       "      <td>0</td>\n",
       "      <td>subject8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167106</th>\n",
       "      <td>1.53220</td>\n",
       "      <td>-9.5966</td>\n",
       "      <td>-0.25618</td>\n",
       "      <td>-0.27273</td>\n",
       "      <td>-0.75985</td>\n",
       "      <td>0.63654</td>\n",
       "      <td>-2.5898</td>\n",
       "      <td>-8.5217</td>\n",
       "      <td>3.83430</td>\n",
       "      <td>-0.88431</td>\n",
       "      <td>-0.848050</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0</td>\n",
       "      <td>subject2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493889</th>\n",
       "      <td>1.78090</td>\n",
       "      <td>-8.5942</td>\n",
       "      <td>-3.97440</td>\n",
       "      <td>-0.41002</td>\n",
       "      <td>-0.55535</td>\n",
       "      <td>-0.78389</td>\n",
       "      <td>-1.0049</td>\n",
       "      <td>-6.8588</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>-0.35686</td>\n",
       "      <td>-0.854210</td>\n",
       "      <td>-0.415950</td>\n",
       "      <td>0</td>\n",
       "      <td>subject4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355024</th>\n",
       "      <td>-0.34940</td>\n",
       "      <td>-9.5201</td>\n",
       "      <td>1.45800</td>\n",
       "      <td>-0.68275</td>\n",
       "      <td>-0.77861</td>\n",
       "      <td>-0.24558</td>\n",
       "      <td>-1.4178</td>\n",
       "      <td>-9.5157</td>\n",
       "      <td>1.43050</td>\n",
       "      <td>-0.12353</td>\n",
       "      <td>-0.967150</td>\n",
       "      <td>-0.497840</td>\n",
       "      <td>0</td>\n",
       "      <td>subject3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213641</th>\n",
       "      <td>-2.48730</td>\n",
       "      <td>-19.2330</td>\n",
       "      <td>3.46140</td>\n",
       "      <td>0.61967</td>\n",
       "      <td>-0.33771</td>\n",
       "      <td>-0.82711</td>\n",
       "      <td>-8.2348</td>\n",
       "      <td>-4.9652</td>\n",
       "      <td>2.48090</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-1.018500</td>\n",
       "      <td>0.079741</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213642</th>\n",
       "      <td>-21.59100</td>\n",
       "      <td>-19.4370</td>\n",
       "      <td>-6.04190</td>\n",
       "      <td>0.61967</td>\n",
       "      <td>-0.33771</td>\n",
       "      <td>-0.82711</td>\n",
       "      <td>-21.3180</td>\n",
       "      <td>-10.2130</td>\n",
       "      <td>3.65600</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-1.018500</td>\n",
       "      <td>0.079741</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213643</th>\n",
       "      <td>7.54330</td>\n",
       "      <td>-19.2450</td>\n",
       "      <td>-2.66800</td>\n",
       "      <td>0.61967</td>\n",
       "      <td>-0.33771</td>\n",
       "      <td>-0.82711</td>\n",
       "      <td>-21.2970</td>\n",
       "      <td>-18.7050</td>\n",
       "      <td>4.46060</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-1.018500</td>\n",
       "      <td>0.079741</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213644</th>\n",
       "      <td>3.01420</td>\n",
       "      <td>-19.3340</td>\n",
       "      <td>-7.70740</td>\n",
       "      <td>0.71058</td>\n",
       "      <td>-0.27017</td>\n",
       "      <td>-0.75442</td>\n",
       "      <td>-21.1380</td>\n",
       "      <td>-18.6980</td>\n",
       "      <td>1.15880</td>\n",
       "      <td>-0.42549</td>\n",
       "      <td>-1.037000</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213645</th>\n",
       "      <td>-2.36980</td>\n",
       "      <td>-19.3000</td>\n",
       "      <td>-4.23870</td>\n",
       "      <td>0.71058</td>\n",
       "      <td>-0.27017</td>\n",
       "      <td>-0.75442</td>\n",
       "      <td>-21.1730</td>\n",
       "      <td>-14.2910</td>\n",
       "      <td>-0.13123</td>\n",
       "      <td>-0.42549</td>\n",
       "      <td>-1.037000</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373195 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              alx      aly      alz      glx      gly      glz      arx  \\\n",
       "154060   -0.68636  -5.2902  4.64530  0.13544 -0.83114 -0.13163  -8.4230   \n",
       "936066    1.00030  -7.7902 -6.74410 -0.26531 -0.14447 -1.09820   2.2046   \n",
       "167106    1.53220  -9.5966 -0.25618 -0.27273 -0.75985  0.63654  -2.5898   \n",
       "493889    1.78090  -8.5942 -3.97440 -0.41002 -0.55535 -0.78389  -1.0049   \n",
       "355024   -0.34940  -9.5201  1.45800 -0.68275 -0.77861 -0.24558  -1.4178   \n",
       "...           ...      ...      ...      ...      ...      ...      ...   \n",
       "1213641  -2.48730 -19.2330  3.46140  0.61967 -0.33771 -0.82711  -8.2348   \n",
       "1213642 -21.59100 -19.4370 -6.04190  0.61967 -0.33771 -0.82711 -21.3180   \n",
       "1213643   7.54330 -19.2450 -2.66800  0.61967 -0.33771 -0.82711 -21.2970   \n",
       "1213644   3.01420 -19.3340 -7.70740  0.71058 -0.27017 -0.75442 -21.1380   \n",
       "1213645  -2.36980 -19.3000 -4.23870  0.71058 -0.27017 -0.75442 -21.1730   \n",
       "\n",
       "             ary      arz      grx       gry       grz  Activity    subject  \n",
       "154060   -6.6402  2.98050 -0.93922  0.090349  0.219830         0   subject1  \n",
       "936066   -7.5497  4.02880 -0.21961 -1.080100  0.303880         0   subject8  \n",
       "167106   -8.5217  3.83430 -0.88431 -0.848050  0.331900         0   subject2  \n",
       "493889   -6.8588  2.11540 -0.35686 -0.854210 -0.415950         0   subject4  \n",
       "355024   -9.5157  1.43050 -0.12353 -0.967150 -0.497840         0   subject3  \n",
       "...          ...      ...      ...       ...       ...       ...        ...  \n",
       "1213641  -4.9652  2.48090 -0.43725 -1.018500  0.079741        12  subject10  \n",
       "1213642 -10.2130  3.65600 -0.43725 -1.018500  0.079741        12  subject10  \n",
       "1213643 -18.7050  4.46060 -0.43725 -1.018500  0.079741        12  subject10  \n",
       "1213644 -18.6980  1.15880 -0.42549 -1.037000  0.084052        12  subject10  \n",
       "1213645 -14.2910 -0.13123 -0.42549 -1.037000  0.084052        12  subject10  \n",
       "\n",
       "[373195 rows x 14 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alx range: -11.47312 to 19.233\n",
      "shape (365733, 14)\n",
      "aly range: -19.379 to 2.447871999999997\n",
      "shape (360018, 14)\n",
      "alz range: -18.95 to 14.19623999999999\n",
      "shape (356270, 14)\n",
      "glx range: -0.74212 to 0.80705\n",
      "shape (349377, 14)\n",
      "gly range: -1.0694 to 0.96623\n",
      "shape (342841, 14)\n",
      "glz range: -1.1061 to 0.8290799999999999\n",
      "shape (337391, 14)\n",
      "arx range: -21.492 to 9.097647999999998\n",
      "shape (332307, 14)\n",
      "ary range: -18.694000000000003 to 11.948059999999998\n",
      "shape (326241, 14)\n",
      "arz range: -10.367 to 11.823119999999996\n",
      "shape (323674, 14)\n",
      "grx range: -1.0196 to 0.95686\n",
      "shape (320188, 14)\n",
      "gry range: -1.1417 to 0.90965\n",
      "shape (315352, 14)\n",
      "grz range: -0.69828 to 1.125\n",
      "shape (310929, 14)\n"
     ]
    }
   ],
   "source": [
    "#Dropping feature have data outside 98% confidence interval\n",
    "df1 = df.copy()\n",
    "for feature in df1.columns[:-2]:\n",
    "  lower_range = np.quantile(df[feature],0.01)\n",
    "  upper_range = np.quantile(df[feature],0.99)\n",
    "  print(feature,'range:',lower_range,'to',upper_range)\n",
    "\n",
    "  df1 = df1.drop(df1[(df1[feature]>upper_range) | (df1[feature]<lower_range)].index, axis=0)\n",
    "  print('shape',df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'Nothing',\n",
    "    1: 'Standing still',  \n",
    "    2: 'Sitting and relaxing', \n",
    "    3: 'Lying down',  \n",
    "    4: 'Walking',  \n",
    "    5: 'Climbing stairs',  \n",
    "    6: 'Waist bends forward',\n",
    "    7: 'Frontal elevation of arms', \n",
    "    8: 'Knees bending (crouching)', \n",
    "    9: 'Cycling', \n",
    "    10: 'Jogging', \n",
    "    11: 'Running', \n",
    "    12: 'Jump front & back' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310929, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((246501, 14), (64428, 14))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "train = df1[(df1['subject'] != 'subject10') & (df1['subject'] != 'subject9')]\n",
    "test = df1.drop(train.index, axis=0)\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246501, 12), (246501,), (64428, 12), (64428,))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['Activity','subject'],axis=1)\n",
    "y_train = train['Activity']\n",
    "X_test = test.drop(['Activity','subject'],axis=1)\n",
    "y_test = test['Activity']\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#function to create time series datset for seuence modeling\n",
    "def create_dataset(X, y, time_steps, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        x = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(x)\n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4929, 100, 12), (4929, 1))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,y_train = create_dataset(X_train, y_train, 100, step=50)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1287, 100, 12), (1287, 1))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test,y_test = create_dataset(X_test, y_test, 100, step=50)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=[100,12]))\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=3, padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.LSTM(64))\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "model.add(layers.Dense(13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(100, 32, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.fc1 = nn.Linear(64*50, 128)\n",
    "        self.fc2 = nn.Linear(128, 13)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(64, 64, batch_first=True)\n",
    "        self.batchnorm = nn.BatchNorm1d(32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batchnorm(self.conv1(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.batchnorm(self.conv2(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32146/220928166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32146/220928166.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_32146/2752476788.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvFL/env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    309\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 310\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float().to(DEVICE)\n",
    "y_train = torch.from_numpy(y_train).long().to(DEVICE)\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float().to(DEVICE)\n",
    "y_test = torch.from_numpy(y_test).long().to(DEVICE)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def train(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, epochs=10):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_train = model(X_train)\n",
    "            y_pred_test = model(X_test)\n",
    "            train_acc.append(accuracy_score(y_train.cpu(), y_pred_train.cpu().argmax(1)))\n",
    "            test_acc.append(accuracy_score(y_test.cpu(), y_pred_test.cpu().argmax(1)))\n",
    "            print('Epoch: {} Train Loss: {:.4f} Train Acc: {:.4f} Test Acc: {:.4f}'.format(epoch, loss.item(), train_acc[-1], test_acc[-1]))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "train_acc, test_acc = train(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, epochs=10)\n",
    "\n",
    "plt.plot(train_acc, label='train')\n",
    "\n",
    "plt.plot(test_acc, label='test')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

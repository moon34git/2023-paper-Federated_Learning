{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "%matplotlib inline\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/mhealth_raw_data.pickle', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     30720\n",
       "2     30720\n",
       "3     30720\n",
       "4     30720\n",
       "9     30720\n",
       "10    30720\n",
       "11    30720\n",
       "5     30720\n",
       "0     30000\n",
       "7     29441\n",
       "8     29337\n",
       "6     28315\n",
       "12    10342\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    " \n",
    "df_majority = df[df.Activity==0]\n",
    "df_minorities = df[df.Activity!=0]\n",
    " \n",
    "df_majority_downsampled = resample(df_majority,n_samples=30000, random_state=42)\n",
    "df = pd.concat([df_majority_downsampled, df_minorities])\n",
    "df.Activity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alx</th>\n",
       "      <th>aly</th>\n",
       "      <th>alz</th>\n",
       "      <th>glx</th>\n",
       "      <th>gly</th>\n",
       "      <th>glz</th>\n",
       "      <th>arx</th>\n",
       "      <th>ary</th>\n",
       "      <th>arz</th>\n",
       "      <th>grx</th>\n",
       "      <th>gry</th>\n",
       "      <th>grz</th>\n",
       "      <th>Activity</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154060</th>\n",
       "      <td>-0.68636</td>\n",
       "      <td>-5.2902</td>\n",
       "      <td>4.64530</td>\n",
       "      <td>0.13544</td>\n",
       "      <td>-0.83114</td>\n",
       "      <td>-0.13163</td>\n",
       "      <td>-8.4230</td>\n",
       "      <td>-6.6402</td>\n",
       "      <td>2.98050</td>\n",
       "      <td>-0.93922</td>\n",
       "      <td>0.090349</td>\n",
       "      <td>0.219830</td>\n",
       "      <td>0</td>\n",
       "      <td>subject1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936066</th>\n",
       "      <td>1.00030</td>\n",
       "      <td>-7.7902</td>\n",
       "      <td>-6.74410</td>\n",
       "      <td>-0.26531</td>\n",
       "      <td>-0.14447</td>\n",
       "      <td>-1.09820</td>\n",
       "      <td>2.2046</td>\n",
       "      <td>-7.5497</td>\n",
       "      <td>4.02880</td>\n",
       "      <td>-0.21961</td>\n",
       "      <td>-1.080100</td>\n",
       "      <td>0.303880</td>\n",
       "      <td>0</td>\n",
       "      <td>subject8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167106</th>\n",
       "      <td>1.53220</td>\n",
       "      <td>-9.5966</td>\n",
       "      <td>-0.25618</td>\n",
       "      <td>-0.27273</td>\n",
       "      <td>-0.75985</td>\n",
       "      <td>0.63654</td>\n",
       "      <td>-2.5898</td>\n",
       "      <td>-8.5217</td>\n",
       "      <td>3.83430</td>\n",
       "      <td>-0.88431</td>\n",
       "      <td>-0.848050</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0</td>\n",
       "      <td>subject2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493889</th>\n",
       "      <td>1.78090</td>\n",
       "      <td>-8.5942</td>\n",
       "      <td>-3.97440</td>\n",
       "      <td>-0.41002</td>\n",
       "      <td>-0.55535</td>\n",
       "      <td>-0.78389</td>\n",
       "      <td>-1.0049</td>\n",
       "      <td>-6.8588</td>\n",
       "      <td>2.11540</td>\n",
       "      <td>-0.35686</td>\n",
       "      <td>-0.854210</td>\n",
       "      <td>-0.415950</td>\n",
       "      <td>0</td>\n",
       "      <td>subject4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355024</th>\n",
       "      <td>-0.34940</td>\n",
       "      <td>-9.5201</td>\n",
       "      <td>1.45800</td>\n",
       "      <td>-0.68275</td>\n",
       "      <td>-0.77861</td>\n",
       "      <td>-0.24558</td>\n",
       "      <td>-1.4178</td>\n",
       "      <td>-9.5157</td>\n",
       "      <td>1.43050</td>\n",
       "      <td>-0.12353</td>\n",
       "      <td>-0.967150</td>\n",
       "      <td>-0.497840</td>\n",
       "      <td>0</td>\n",
       "      <td>subject3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213641</th>\n",
       "      <td>-2.48730</td>\n",
       "      <td>-19.2330</td>\n",
       "      <td>3.46140</td>\n",
       "      <td>0.61967</td>\n",
       "      <td>-0.33771</td>\n",
       "      <td>-0.82711</td>\n",
       "      <td>-8.2348</td>\n",
       "      <td>-4.9652</td>\n",
       "      <td>2.48090</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-1.018500</td>\n",
       "      <td>0.079741</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213642</th>\n",
       "      <td>-21.59100</td>\n",
       "      <td>-19.4370</td>\n",
       "      <td>-6.04190</td>\n",
       "      <td>0.61967</td>\n",
       "      <td>-0.33771</td>\n",
       "      <td>-0.82711</td>\n",
       "      <td>-21.3180</td>\n",
       "      <td>-10.2130</td>\n",
       "      <td>3.65600</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-1.018500</td>\n",
       "      <td>0.079741</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213643</th>\n",
       "      <td>7.54330</td>\n",
       "      <td>-19.2450</td>\n",
       "      <td>-2.66800</td>\n",
       "      <td>0.61967</td>\n",
       "      <td>-0.33771</td>\n",
       "      <td>-0.82711</td>\n",
       "      <td>-21.2970</td>\n",
       "      <td>-18.7050</td>\n",
       "      <td>4.46060</td>\n",
       "      <td>-0.43725</td>\n",
       "      <td>-1.018500</td>\n",
       "      <td>0.079741</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213644</th>\n",
       "      <td>3.01420</td>\n",
       "      <td>-19.3340</td>\n",
       "      <td>-7.70740</td>\n",
       "      <td>0.71058</td>\n",
       "      <td>-0.27017</td>\n",
       "      <td>-0.75442</td>\n",
       "      <td>-21.1380</td>\n",
       "      <td>-18.6980</td>\n",
       "      <td>1.15880</td>\n",
       "      <td>-0.42549</td>\n",
       "      <td>-1.037000</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213645</th>\n",
       "      <td>-2.36980</td>\n",
       "      <td>-19.3000</td>\n",
       "      <td>-4.23870</td>\n",
       "      <td>0.71058</td>\n",
       "      <td>-0.27017</td>\n",
       "      <td>-0.75442</td>\n",
       "      <td>-21.1730</td>\n",
       "      <td>-14.2910</td>\n",
       "      <td>-0.13123</td>\n",
       "      <td>-0.42549</td>\n",
       "      <td>-1.037000</td>\n",
       "      <td>0.084052</td>\n",
       "      <td>12</td>\n",
       "      <td>subject10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373195 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              alx      aly      alz      glx      gly      glz      arx  \\\n",
       "154060   -0.68636  -5.2902  4.64530  0.13544 -0.83114 -0.13163  -8.4230   \n",
       "936066    1.00030  -7.7902 -6.74410 -0.26531 -0.14447 -1.09820   2.2046   \n",
       "167106    1.53220  -9.5966 -0.25618 -0.27273 -0.75985  0.63654  -2.5898   \n",
       "493889    1.78090  -8.5942 -3.97440 -0.41002 -0.55535 -0.78389  -1.0049   \n",
       "355024   -0.34940  -9.5201  1.45800 -0.68275 -0.77861 -0.24558  -1.4178   \n",
       "...           ...      ...      ...      ...      ...      ...      ...   \n",
       "1213641  -2.48730 -19.2330  3.46140  0.61967 -0.33771 -0.82711  -8.2348   \n",
       "1213642 -21.59100 -19.4370 -6.04190  0.61967 -0.33771 -0.82711 -21.3180   \n",
       "1213643   7.54330 -19.2450 -2.66800  0.61967 -0.33771 -0.82711 -21.2970   \n",
       "1213644   3.01420 -19.3340 -7.70740  0.71058 -0.27017 -0.75442 -21.1380   \n",
       "1213645  -2.36980 -19.3000 -4.23870  0.71058 -0.27017 -0.75442 -21.1730   \n",
       "\n",
       "             ary      arz      grx       gry       grz  Activity    subject  \n",
       "154060   -6.6402  2.98050 -0.93922  0.090349  0.219830         0   subject1  \n",
       "936066   -7.5497  4.02880 -0.21961 -1.080100  0.303880         0   subject8  \n",
       "167106   -8.5217  3.83430 -0.88431 -0.848050  0.331900         0   subject2  \n",
       "493889   -6.8588  2.11540 -0.35686 -0.854210 -0.415950         0   subject4  \n",
       "355024   -9.5157  1.43050 -0.12353 -0.967150 -0.497840         0   subject3  \n",
       "...          ...      ...      ...       ...       ...       ...        ...  \n",
       "1213641  -4.9652  2.48090 -0.43725 -1.018500  0.079741        12  subject10  \n",
       "1213642 -10.2130  3.65600 -0.43725 -1.018500  0.079741        12  subject10  \n",
       "1213643 -18.7050  4.46060 -0.43725 -1.018500  0.079741        12  subject10  \n",
       "1213644 -18.6980  1.15880 -0.42549 -1.037000  0.084052        12  subject10  \n",
       "1213645 -14.2910 -0.13123 -0.42549 -1.037000  0.084052        12  subject10  \n",
       "\n",
       "[373195 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alx range: -11.47312 to 19.233\n",
      "shape (365733, 14)\n",
      "aly range: -19.379 to 2.447871999999997\n",
      "shape (360018, 14)\n",
      "alz range: -18.95 to 14.19623999999999\n",
      "shape (356270, 14)\n",
      "glx range: -0.74212 to 0.80705\n",
      "shape (349377, 14)\n",
      "gly range: -1.0694 to 0.96623\n",
      "shape (342841, 14)\n",
      "glz range: -1.1061 to 0.8290799999999999\n",
      "shape (337391, 14)\n",
      "arx range: -21.492 to 9.097647999999998\n",
      "shape (332307, 14)\n",
      "ary range: -18.694000000000003 to 11.948059999999998\n",
      "shape (326241, 14)\n",
      "arz range: -10.367 to 11.823119999999996\n",
      "shape (323674, 14)\n",
      "grx range: -1.0196 to 0.95686\n",
      "shape (320188, 14)\n",
      "gry range: -1.1417 to 0.90965\n",
      "shape (315352, 14)\n",
      "grz range: -0.69828 to 1.125\n",
      "shape (310929, 14)\n"
     ]
    }
   ],
   "source": [
    "#Dropping feature have data outside 98% confidence interval\n",
    "df1 = df.copy()\n",
    "for feature in df1.columns[:-2]:\n",
    "  lower_range = np.quantile(df[feature],0.01)\n",
    "  upper_range = np.quantile(df[feature],0.99)\n",
    "  print(feature,'range:',lower_range,'to',upper_range)\n",
    "\n",
    "  df1 = df1.drop(df1[(df1[feature]>upper_range) | (df1[feature]<lower_range)].index, axis=0)\n",
    "  print('shape',df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'Nothing',\n",
    "    1: 'Standing still',  \n",
    "    2: 'Sitting and relaxing', \n",
    "    3: 'Lying down',  \n",
    "    4: 'Walking',  \n",
    "    5: 'Climbing stairs',  \n",
    "    6: 'Waist bends forward',\n",
    "    7: 'Frontal elevation of arms', \n",
    "    8: 'Knees bending (crouching)', \n",
    "    9: 'Cycling', \n",
    "    10: 'Jogging', \n",
    "    11: 'Running', \n",
    "    12: 'Jump front & back' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310929, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((246501, 14), (64428, 14))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "train = df1[(df1['subject'] != 'subject10') & (df1['subject'] != 'subject9')]\n",
    "test = df1.drop(train.index, axis=0)\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246501, 12), (246501,), (64428, 12), (64428,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['Activity','subject'],axis=1)\n",
    "y_train = train['Activity']\n",
    "X_test = test.drop(['Activity','subject'],axis=1)\n",
    "y_test = test['Activity']\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#function to create time series datset for seuence modeling\n",
    "def create_dataset(X, y, time_steps, step=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(0, len(X) - time_steps, step):\n",
    "        x = X.iloc[i:(i + time_steps)].values\n",
    "        labels = y.iloc[i: i + time_steps]\n",
    "        Xs.append(x)\n",
    "        ys.append(stats.mode(labels)[0][0])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4929, 100, 12), (4929, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_copy ,y_train_copy = create_dataset(X_train, y_train, 100, step=50)\n",
    "X_train_copy.shape, y_train_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1287, 100, 12), (1287, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_copy,y_test_copy = create_dataset(X_test, y_test, 100, step=50)\n",
    "X_test_copy.shape, y_test_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=[100,12]))\n",
    "model.add(layers.Conv1D(filters=32, kernel_size=3, padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.Conv1D(filters=64, kernel_size=3, padding=\"same\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPool1D(2))\n",
    "model.add(layers.LSTM(64))\n",
    "model.add(layers.Dense(units=128, activation='relu'))\n",
    "model.add(layers.Dense(13, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(100, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstm): LSTM(64, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=100, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=32)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=64)\n",
    "        \n",
    "        self.max_pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=13)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1) # Permute to match LSTM input shape\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:, -1, :] # Only take the last output of the LSTM\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(100, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (lstm): LSTM(64, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4929, 100, 12]),\n",
       " torch.Size([4929, 1]),\n",
       " torch.Size([1287, 100, 12]),\n",
       " torch.Size([1287, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "X_train1 = torch.from_numpy(X_train_copy).float().to(DEVICE)\n",
    "y_train1 = torch.from_numpy(y_train_copy).long().to(DEVICE)\n",
    "\n",
    "X_test1 = torch.from_numpy(X_test_copy).float().to(DEVICE)\n",
    "y_test1 = torch.from_numpy(y_test_copy).long().to(DEVICE)\n",
    "\n",
    "X_train1.shape, y_train1.shape, X_test1.shape, y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -0.6864,  -5.2902,   4.6453,  ...,  -0.9392,   0.0903,   0.2198],\n",
       "         [  1.0003,  -7.7902,  -6.7441,  ...,  -0.2196,  -1.0801,   0.3039],\n",
       "         [  1.5322,  -9.5966,  -0.2562,  ...,  -0.8843,  -0.8480,   0.3319],\n",
       "         ...,\n",
       "         [  3.6543,  -9.0272,  -0.7377,  ...,  -0.0902,  -0.8727,  -0.6703],\n",
       "         [  0.9086,  -9.5871,   1.6860,  ...,  -0.6882,  -0.8275,   0.0905],\n",
       "         [  0.3465,  -7.6891,  -0.5893,  ...,  -0.1765,  -1.0267,  -0.3944]],\n",
       "\n",
       "        [[  0.8306,  -5.2852,  -0.7976,  ...,  -0.1863,  -0.7680,   0.8922],\n",
       "         [  2.0891,  -9.5404,   1.4085,  ...,  -0.1863,   0.0308,   1.1228],\n",
       "         [  0.3504,  -8.0943,   2.4530,  ...,  -0.7490,   0.2382,   0.5172],\n",
       "         ...,\n",
       "         [-11.3560,  -8.9798,  -8.8751,  ...,  -0.3823,  -0.6037,  -0.5840],\n",
       "         [  1.9896, -10.3180,  -0.1314,  ...,  -0.5941,   0.1725,   1.0108],\n",
       "         [ -0.0558,  -9.4624,   1.2867,  ...,  -0.2000,  -0.7988,   0.8082]],\n",
       "\n",
       "        [[  0.1517,  -9.7090,   1.3807,  ...,  -0.8745,  -0.6058,  -0.0323],\n",
       "         [  3.9136,  -6.8346,  -4.2505,  ...,  -0.3118,  -0.4497,   1.0216],\n",
       "         [  1.1436,  -9.6468,   1.6541,  ...,  -0.0373,  -1.0390,  -0.3901],\n",
       "         ...,\n",
       "         [  3.9128,  -9.2538,  -0.6319,  ...,  -0.4529,  -0.6838,   0.8384],\n",
       "         [  0.2074,  -9.7943,   1.7624,  ...,  -0.3235,  -0.9261,  -0.4203],\n",
       "         [  0.6810, -11.3610,  -1.4258,  ...,  -0.0490,  -1.1376,   0.3901]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0.4968, -11.3270, -18.7910,  ...,  -0.6294,   0.2649,   0.9569],\n",
       "         [  4.8460,   0.2335, -18.2320,  ...,  -0.7372,   0.0246,   0.9073],\n",
       "         [ -3.0416,  -3.0557, -18.4440,  ...,  -0.7372,   0.0246,   0.9073],\n",
       "         ...,\n",
       "         [ -0.1875,  -8.0577, -18.6440,  ...,  -0.5490,   0.1088,   1.0323],\n",
       "         [  7.7780, -14.5320,   8.1637,  ...,  -0.7863,  -0.0595,   0.8384],\n",
       "         [ 18.4030, -12.5450, -10.9740,  ...,  -0.7980,   0.1027,   0.8039]],\n",
       "\n",
       "        [[  9.9573, -10.4630, -11.6740,  ...,  -0.8843,   0.0390,   0.6897],\n",
       "         [  9.3952,  -3.5656, -12.0010,  ...,  -0.8843,   0.0390,   0.6897],\n",
       "         [  9.0974, -11.2720,  -0.5143,  ...,  -0.6392,   0.6119,   0.7371],\n",
       "         ...,\n",
       "         [ 13.0060, -19.0660,  13.1770,  ...,  -0.6843,   0.6345,  -0.5065],\n",
       "         [ 18.6870, -15.5750,  -3.9981,  ...,  -0.7039,   0.3901,  -0.6875],\n",
       "         [ -6.4018, -19.1560,  13.1140,  ...,  -0.7372,   0.2936,  -0.6897]],\n",
       "\n",
       "        [[ -0.2274,  -8.0010,   0.8893,  ...,  -0.6098,   0.5154,   0.8276],\n",
       "         [  9.0041, -12.7240,  -3.1295,  ...,  -0.6098,   0.5154,   0.8276],\n",
       "         [  7.8632, -12.4730,  -4.7221,  ...,  -0.6098,   0.5154,   0.8276],\n",
       "         ...,\n",
       "         [  5.7282,  -1.1482,  -6.8960,  ...,  -0.7078,   0.4353,  -0.6832],\n",
       "         [  7.2772,  -1.4694,  -4.3653,  ...,  -0.7412,   0.3634,  -0.6638],\n",
       "         [  4.2217, -18.8880,   3.2853,  ...,  -0.7235,   0.2936,  -0.6875]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 3/100 [00:00<00:05, 18.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 2.5650 Train Acc: 0.1674 Test Acc: 0.2036\n",
      "Epoch: 1 Train Loss: 2.5637 Train Acc: 0.1601 Test Acc: 0.2067\n",
      "Epoch: 2 Train Loss: 2.5625 Train Acc: 0.1580 Test Acc: 0.2168\n",
      "Epoch: 3 Train Loss: 2.5612 Train Acc: 0.1887 Test Acc: 0.2385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 9/100 [00:00<00:03, 25.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Train Loss: 2.5598 Train Acc: 0.1864 Test Acc: 0.2230\n",
      "Epoch: 5 Train Loss: 2.5582 Train Acc: 0.1804 Test Acc: 0.1989\n",
      "Epoch: 6 Train Loss: 2.5562 Train Acc: 0.1952 Test Acc: 0.1841\n",
      "Epoch: 7 Train Loss: 2.5541 Train Acc: 0.2128 Test Acc: 0.1515\n",
      "Epoch: 8 Train Loss: 2.5515 Train Acc: 0.2439 Test Acc: 0.2028\n",
      "Epoch: 9 Train Loss: 2.5484 Train Acc: 0.2552 Test Acc: 0.2044\n",
      "Epoch: 10 Train Loss: 2.5448 Train Acc: 0.2844 Test Acc: 0.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 17/100 [00:00<00:02, 31.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Train Loss: 2.5406 Train Acc: 0.2917 Test Acc: 0.1981\n",
      "Epoch: 12 Train Loss: 2.5358 Train Acc: 0.3041 Test Acc: 0.2510\n",
      "Epoch: 13 Train Loss: 2.5302 Train Acc: 0.2952 Test Acc: 0.2626\n",
      "Epoch: 14 Train Loss: 2.5237 Train Acc: 0.2853 Test Acc: 0.2696\n",
      "Epoch: 15 Train Loss: 2.5164 Train Acc: 0.2944 Test Acc: 0.2704\n",
      "Epoch: 16 Train Loss: 2.5082 Train Acc: 0.3132 Test Acc: 0.3077\n",
      "Epoch: 17 Train Loss: 2.4992 Train Acc: 0.2990 Test Acc: 0.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:00<00:02, 33.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 Train Loss: 2.4895 Train Acc: 0.2767 Test Acc: 0.2844\n",
      "Epoch: 19 Train Loss: 2.4794 Train Acc: 0.2672 Test Acc: 0.2844\n",
      "Epoch: 20 Train Loss: 2.4692 Train Acc: 0.2627 Test Acc: 0.2844\n",
      "Epoch: 21 Train Loss: 2.4592 Train Acc: 0.2633 Test Acc: 0.2844\n",
      "Epoch: 22 Train Loss: 2.4495 Train Acc: 0.2633 Test Acc: 0.2844\n",
      "Epoch: 23 Train Loss: 2.4401 Train Acc: 0.2635 Test Acc: 0.2844\n",
      "Epoch: 24 Train Loss: 2.4311 Train Acc: 0.2635 Test Acc: 0.2844\n",
      "Epoch: 25 Train Loss: 2.4222 Train Acc: 0.2637 Test Acc: 0.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [00:01<00:01, 35.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 Train Loss: 2.4135 Train Acc: 0.2639 Test Acc: 0.2844\n",
      "Epoch: 27 Train Loss: 2.4046 Train Acc: 0.2642 Test Acc: 0.2844\n",
      "Epoch: 28 Train Loss: 2.3955 Train Acc: 0.2654 Test Acc: 0.2875\n",
      "Epoch: 29 Train Loss: 2.3865 Train Acc: 0.2715 Test Acc: 0.2914\n",
      "Epoch: 30 Train Loss: 2.3776 Train Acc: 0.2812 Test Acc: 0.2976\n",
      "Epoch: 31 Train Loss: 2.3690 Train Acc: 0.2905 Test Acc: 0.3077\n",
      "Epoch: 32 Train Loss: 2.3600 Train Acc: 0.3009 Test Acc: 0.3256\n",
      "Epoch: 33 Train Loss: 2.3508 Train Acc: 0.3161 Test Acc: 0.3349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [00:01<00:01, 36.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 Train Loss: 2.3409 Train Acc: 0.3352 Test Acc: 0.3473\n",
      "Epoch: 35 Train Loss: 2.3306 Train Acc: 0.3709 Test Acc: 0.3737\n",
      "Epoch: 36 Train Loss: 2.3203 Train Acc: 0.3885 Test Acc: 0.3963\n",
      "Epoch: 37 Train Loss: 2.3094 Train Acc: 0.4256 Test Acc: 0.4577\n",
      "Epoch: 38 Train Loss: 2.2976 Train Acc: 0.4480 Test Acc: 0.4911\n",
      "Epoch: 39 Train Loss: 2.2855 Train Acc: 0.4538 Test Acc: 0.4996\n",
      "Epoch: 40 Train Loss: 2.2724 Train Acc: 0.4733 Test Acc: 0.5152\n",
      "Epoch: 41 Train Loss: 2.2594 Train Acc: 0.4784 Test Acc: 0.5167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:01<00:01, 36.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 Train Loss: 2.2467 Train Acc: 0.4825 Test Acc: 0.5190\n",
      "Epoch: 43 Train Loss: 2.2351 Train Acc: 0.4827 Test Acc: 0.5152\n",
      "Epoch: 44 Train Loss: 2.2244 Train Acc: 0.4865 Test Acc: 0.5190\n",
      "Epoch: 45 Train Loss: 2.2141 Train Acc: 0.4863 Test Acc: 0.5214\n",
      "Epoch: 46 Train Loss: 2.2040 Train Acc: 0.4871 Test Acc: 0.5206\n",
      "Epoch: 47 Train Loss: 2.1942 Train Acc: 0.4881 Test Acc: 0.5198\n",
      "Epoch: 48 Train Loss: 2.1844 Train Acc: 0.4869 Test Acc: 0.5167\n",
      "Epoch: 49 Train Loss: 2.1753 Train Acc: 0.4867 Test Acc: 0.5245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [00:01<00:01, 36.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 Train Loss: 2.1692 Train Acc: 0.4940 Test Acc: 0.5330\n",
      "Epoch: 51 Train Loss: 2.1576 Train Acc: 0.5070 Test Acc: 0.5835\n",
      "Epoch: 52 Train Loss: 2.1450 Train Acc: 0.3972 Test Acc: 0.4095\n",
      "Epoch: 53 Train Loss: 2.1466 Train Acc: 0.5890 Test Acc: 0.6333\n",
      "Epoch: 54 Train Loss: 2.1228 Train Acc: 0.6070 Test Acc: 0.6791\n",
      "Epoch: 55 Train Loss: 2.1172 Train Acc: 0.6470 Test Acc: 0.6799\n",
      "Epoch: 56 Train Loss: 2.0973 Train Acc: 0.4782 Test Acc: 0.4328\n",
      "Epoch: 57 Train Loss: 2.0942 Train Acc: 0.5827 Test Acc: 0.6123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [00:01<00:00, 36.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58 Train Loss: 2.0769 Train Acc: 0.7377 Test Acc: 0.7133\n",
      "Epoch: 59 Train Loss: 2.0575 Train Acc: 0.7279 Test Acc: 0.7156\n",
      "Epoch: 60 Train Loss: 2.0508 Train Acc: 0.7389 Test Acc: 0.6752\n",
      "Epoch: 61 Train Loss: 2.0313 Train Acc: 0.6892 Test Acc: 0.6200\n",
      "Epoch: 62 Train Loss: 2.0290 Train Acc: 0.7306 Test Acc: 0.7086\n",
      "Epoch: 63 Train Loss: 2.0040 Train Acc: 0.7221 Test Acc: 0.7047\n",
      "Epoch: 64 Train Loss: 1.9935 Train Acc: 0.7395 Test Acc: 0.7211\n",
      "Epoch: 65 Train Loss: 1.9732 Train Acc: 0.7241 Test Acc: 0.6294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:02<00:00, 36.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 Train Loss: 1.9620 Train Acc: 0.7651 Test Acc: 0.6908\n",
      "Epoch: 67 Train Loss: 1.9433 Train Acc: 0.7738 Test Acc: 0.6799\n",
      "Epoch: 68 Train Loss: 1.9342 Train Acc: 0.7910 Test Acc: 0.7203\n",
      "Epoch: 69 Train Loss: 1.9239 Train Acc: 0.7971 Test Acc: 0.7009\n",
      "Epoch: 70 Train Loss: 1.9123 Train Acc: 0.7894 Test Acc: 0.6915\n",
      "Epoch: 71 Train Loss: 1.9033 Train Acc: 0.8162 Test Acc: 0.7529\n",
      "Epoch: 72 Train Loss: 1.8940 Train Acc: 0.8221 Test Acc: 0.7615\n",
      "Epoch: 73 Train Loss: 1.8879 Train Acc: 0.8255 Test Acc: 0.7653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [00:02<00:00, 37.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 Train Loss: 1.8819 Train Acc: 0.8294 Test Acc: 0.7677\n",
      "Epoch: 75 Train Loss: 1.8741 Train Acc: 0.8320 Test Acc: 0.7700\n",
      "Epoch: 76 Train Loss: 1.8690 Train Acc: 0.8365 Test Acc: 0.7723\n",
      "Epoch: 77 Train Loss: 1.8641 Train Acc: 0.8405 Test Acc: 0.7770\n",
      "Epoch: 78 Train Loss: 1.8605 Train Acc: 0.8444 Test Acc: 0.7848\n",
      "Epoch: 79 Train Loss: 1.8567 Train Acc: 0.8468 Test Acc: 0.7972\n",
      "Epoch: 80 Train Loss: 1.8539 Train Acc: 0.8489 Test Acc: 0.7995\n",
      "Epoch: 81 Train Loss: 1.8512 Train Acc: 0.8507 Test Acc: 0.8011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [00:02<00:00, 37.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82 Train Loss: 1.8490 Train Acc: 0.8521 Test Acc: 0.8019\n",
      "Epoch: 83 Train Loss: 1.8469 Train Acc: 0.8537 Test Acc: 0.8081\n",
      "Epoch: 84 Train Loss: 1.8451 Train Acc: 0.8549 Test Acc: 0.8135\n",
      "Epoch: 85 Train Loss: 1.8436 Train Acc: 0.8551 Test Acc: 0.8197\n",
      "Epoch: 86 Train Loss: 1.8422 Train Acc: 0.8555 Test Acc: 0.8213\n",
      "Epoch: 87 Train Loss: 1.8412 Train Acc: 0.8560 Test Acc: 0.8252\n",
      "Epoch: 88 Train Loss: 1.8403 Train Acc: 0.8562 Test Acc: 0.8283\n",
      "Epoch: 89 Train Loss: 1.8394 Train Acc: 0.8560 Test Acc: 0.8291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:02<00:00, 37.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 Train Loss: 1.8387 Train Acc: 0.8564 Test Acc: 0.8275\n",
      "Epoch: 91 Train Loss: 1.8380 Train Acc: 0.8566 Test Acc: 0.8275\n",
      "Epoch: 92 Train Loss: 1.8373 Train Acc: 0.8566 Test Acc: 0.8267\n",
      "Epoch: 93 Train Loss: 1.8367 Train Acc: 0.8568 Test Acc: 0.8291\n",
      "Epoch: 94 Train Loss: 1.8362 Train Acc: 0.8570 Test Acc: 0.8298\n",
      "Epoch: 95 Train Loss: 1.8357 Train Acc: 0.8576 Test Acc: 0.8314\n",
      "Epoch: 96 Train Loss: 1.8352 Train Acc: 0.8578 Test Acc: 0.8322\n",
      "Epoch: 97 Train Loss: 1.8349 Train Acc: 0.8580 Test Acc: 0.8329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:02<00:00, 34.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 Train Loss: 1.8345 Train Acc: 0.8580 Test Acc: 0.8337\n",
      "Epoch: 99 Train Loss: 1.8342 Train Acc: 0.8578 Test Acc: 0.8337\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "def train(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, epochs=10):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_loss =[]\n",
    "    test_loss = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred, y_train.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_train = model(X_train)\n",
    "            y_pred_test = model(X_test)\n",
    "            train_acc.append(accuracy_score(y_train.cpu(), y_pred_train.cpu().argmax(1)))\n",
    "            test_acc.append(accuracy_score(y_test.cpu(), y_pred_test.cpu().argmax(1)))\n",
    "            train_loss.append(loss.item())\n",
    "            print('Epoch: {} Train Loss: {:.4f} Train Acc: {:.4f} Test Acc: {:.4f}'.format(epoch, loss.item(), train_acc[-1], test_acc[-1]))\n",
    "    return train_acc, test_acc, train_loss\n",
    "\n",
    "\n",
    "train_acc, test_acc, train_loss = train(model, X_train1, y_train1, X_test1, y_test1, optimizer, loss_fn, epochs=100)\n",
    "\n",
    "plt.plot(train_acc, label='train', color = 'b')\n",
    "\n",
    "plt.plot(test_acc, label='test', color = 'r')\n",
    "\n",
    "plt.plot(train_loss, label = 'train_loss', color = 'yellow')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
